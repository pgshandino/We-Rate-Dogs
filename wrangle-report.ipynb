{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03156e8a",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e581bd",
   "metadata": {},
   "source": [
    "The wrangling process for this project started with the data gathering process to assessing process and finally, the cleaning process. To ensure the successful completion of this project, all data wrangling process were keenly followed and documented appropriately. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98865142",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0205e64",
   "metadata": {},
   "source": [
    "The data gathering process involved collecting data from three different sources and under three different format. They are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61b214",
   "metadata": {},
   "source": [
    "- Downloaded comma seperated values (csv) file: the file provided for downloaded was downloaded to my local machine and subsequently loaded for use into the ipythin notebook or data wrangling and analysis.\n",
    "- Programatically downloading iles from the internet: the next file was programatically downloaded using python's request module. The program successfully downloaded the file and saved it on the local machine whech is then used for wrangling and analysis.\n",
    "- Application Programming Interface (API): the twitter API was used to get the retweet count and like count for every tweet that are present in the file downloaaded in 1 above. Tweepy is used to query the twitter API and subsequently saved as a txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f4baa",
   "metadata": {},
   "source": [
    "## Assessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77440131",
   "metadata": {},
   "source": [
    "The assessing process involved two methods namely:\n",
    "- __Visual assessment__: this is the method where the assessment is carried out my manually assessing the data using vsiaul technique. It is good for picking very obvious data quality and tidiness issues. It is fast and does not require any special skill to carry out. \n",
    "- __Programatic assessment__: the programatic assessment involve the use of specialised methods and functions e.g. pandas describe() method, info(), etc.\n",
    "\n",
    "For each of the assessment method carried out, the issues noted were documented and categorized into clean(quality) issues and tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6afca50",
   "metadata": {},
   "source": [
    "The assessment carried out resulted in the following findings\n",
    "- Improper names recoreded in the name column of the enhanced table (a, an, None)\n",
    "- Incorrect data type for the timestamp column in the enhanced table\n",
    "- Denominator issue, cases where the denominator is zero hence resulting in a zero division error\n",
    "- Unclean source column consisting of both text and url\n",
    "- cases where the prediction isn't dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5f3d2",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632139f",
   "metadata": {},
   "source": [
    "This section is dedicated to cleaning the data per the issues noted during the assessing phase. The process is  made up of three steps namely:\n",
    "- __Define__: here you define the the issue in a sentence or two.\n",
    "- __Code__: this is where you execute the code that solves the issue at hand\n",
    "- __Test__: here I test to ensure that the code executed without any error and that the data is as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c847383",
   "metadata": {},
   "source": [
    "The cleaning process addressed the issue mentioned above for example\n",
    "- The timestamp column is parsed as a datatime\n",
    "- The name column is fixed\n",
    "- The issue with the denominator is fixed with the proper denominator\n",
    "- The source column is split into text and url\n",
    "- observations that are not dogs are droped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
